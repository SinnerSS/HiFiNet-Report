Fault diagnosis in WSNs has been extensively studied using both traditional rule-based/statistical methods and machine learning (ML) techniques. In non-ML approaches, sensors often use fixed thresholds, mathematical models, or combinatorial tests to identify anomalies. For example, Panda et al. proposed a fault detection algorithm based on z-score function \cite{Panda2014}. Ahmad et al. proposed Kalman filtering as a lightweight anomaly detector in WSNs, but pure Kalman models degrade under fluctuating conditions \cite{Ahmad2024}. These methods typically require hand-tuned parameters and can yield high false alarms when environmental noise is high \cite{Muhammed2017, Zhang2018}. In contrast, ML-based approaches learn patterns from data. ML methods can automatically capture complex patterns in sensor readings, improving outlier detection without explicit rules. Saeed et al. implemented extremely randomized trees using data collected from Telos B motes and evaluate against support vector machine, multilayer perceptron, random forest, decision tree, and extra-trees \cite{Saeed2021}. ML models often achieve high detection accuracy and F1-scores, but require representative training data and incur higher computational cost.

WSN fault detection architectures are typically classified as centralized, distributed, or self-diagnosis schemes \cite{Takele2024, Prasad2023}. In centralized schemes, all sensor nodes send status reports or readings to a base station (sink), which performs fault analysis \cite{Panda2014}. This simplifies the detection logic but incurs high communication overhead: as the network scales, the sink must process many messages, leading to increased latency and limited real-time applicability \cite{Muhammed2017, Zhang2018}. By contrast, self-diagnosis has each node monitor its own status (e.g., battery level or sensor output) and detect local faults. Prasad et al. presented a deep belief network for time-based fault classification using each node data independently \cite{Prasad2023}. Distributed strategies involve neighbors or cluster-heads collaborating to detect faults. For example, nodes can mutually cross-check readings or vote on anomalies, and cluster-heads can aggregate data for local inference. These decentralized methods improve detection accuracy (errors are confirmed by multiple nodes) and scale better via clustering, but they consume extra energy and bandwidth for peer communication. In particular, Adday et al. note that cluster-based diagnosis can reduce communication relative to flat schemes and improve scalability \cite{Adday2022}.

Recent advances have explored hierarchical and hybrid techniques that fuse multiple levels of analysis and feature types. Hierarchical WSN architectures (e.g. clustering) naturally allow multi-stage diagnosis, where cluster-heads perform local detection and report to higher layers. Hybrid information-based method combine expert knowledge with quantitive data using many different algorithms. Shi et al. employed a belief rule base with adaptive attribute weights to improve on traditional static rule base \cite{Shi2024}. Importantly, this study emphasize that sensor data possess strong temporal and spatial correlations, and that fault features should capture both aspects. These efforts suggest a trend toward spatio-temporal fusion: e.g. using time-series prediction at each node together with spatial neighbor-consensus. Nevertheless, truly integrated models that jointly leverage per-node temporal dynamics and network-wide spatial context are still rare in the literature. HiFiNet is motivated by this gap, seeking to hierarchically combine temporal modeling (autoregressive encoding at nodes) with spatial modeling (graph-based fusion across nodes).
